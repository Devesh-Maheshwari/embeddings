{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e37390a",
   "metadata": {},
   "source": [
    "# Word2Vec Visualization\n",
    "\n",
    "This notebook visualizes Word2Vec embeddings and their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f2fd3",
   "metadata": {},
   "source": [
    "CBOW → smooth context, good for frequent words <br>\n",
    "SGNS → better for rare words & topic cluster sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741abb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/Patron/github-projects/embeddings\")\n",
    "from pretraining.word2vec.skipgram import SkipGramSGNS\n",
    "\n",
    "model = SkipGramSGNS.load('../../results/skipgram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a37e0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPGRAM TOP: king ['ansel', 'jacaranda', 'nazwy', 'chanda', 'fforde', 'king', 'guerin', 'arrondissement', 'pinakothek', 'jeziora']\n",
      "CBOW TOP    : king ['nathaniel', 'andre', 'comte', 'algeria', 'anchor', 'christie', 'asteroid', 'rand', 'businessman', 'huxley']\n",
      "\n",
      "SKIPGRAM TOP: queen ['ansel', 'fforde', 'nazwy', 'puntarenas', 'pinakothek', 'guerin', 'jacaranda', 'arrondissement', 'macleish', 'farquhar']\n",
      "CBOW TOP    : queen ['nathaniel', 'comte', 'andre', 'rand', 'algeria', 'anchor', 'willard', 'huxley', 'christie', 'asteroid']\n",
      "\n",
      "SKIPGRAM TOP: prince ['ansel', 'puntarenas', 'fforde', 'nazwy', 'cisalpine', 'macleish', 'ergine', 'parana', 'schwarzenberg', 'modernisme']\n",
      "CBOW TOP    : prince ['nathaniel', 'comte', 'andre', 'rand', 'algeria', 'anchor', 'willard', 'christie', 'asteroid', 'huxley']\n",
      "\n",
      "SKIPGRAM TOP: emperor ['roman', 'brigantes', 'puntarenas', 'lacedaemon', 'punning', 'beholden', 'ansel', 'tigran', 'jacaranda', 'ojos']\n",
      "CBOW TOP    : emperor ['nathaniel', 'comte', 'andre', 'algeria', 'anchor', 'rand', 'asteroid', 'christie', 'willard', 'huxley']\n",
      "\n",
      "SKIPGRAM TOP: france ['united', 'raspberries', 'consultum', 'apparatchiks', 'upi', 'sleng', 'eso', 'south', 'scm', 'bmg']\n",
      "CBOW TOP    : france ['nathaniel', 'andre', 'comte', 'algeria', 'rand', 'anchor', 'christie', 'asteroid', 'willard', 'alaska']\n",
      "\n",
      "SKIPGRAM TOP: germany ['united', 'wieliczka', 'raspberries', 'pinakothek', 'upi', 'nocturnes', 'consultum', 'apparatchiks', 'neuhaus', 'war']\n",
      "CBOW TOP    : germany ['nathaniel', 'algeria', 'comte', 'andre', 'rand', 'anchor', 'willard', 'alaska', 'christie', 'huxley']\n",
      "\n",
      "SKIPGRAM TOP: england ['wieliczka', 'pinakothek', 'nazwy', 'ladysmith', 'citta', 'upi', 'olympiads', 'valli', 'united', 'hibbard']\n",
      "CBOW TOP    : england ['nathaniel', 'comte', 'andre', 'algeria', 'rand', 'anchor', 'willard', 'christie', 'huxley', 'asteroid']\n",
      "\n",
      "SKIPGRAM TOP: russia ['united', 'wieliczka', 'raspberries', 'south', 'north', 'vampira', 'pinakothek', 'sleng', 'cucullatus', 'upi']\n",
      "CBOW TOP    : russia ['nathaniel', 'algeria', 'comte', 'andre', 'rand', 'anchor', 'willard', 'christie', 'asteroid', 'alaska']\n",
      "\n",
      "SKIPGRAM TOP: christianity ['roman', 'th', 'lampooning', 'catholic', 'ancient', 'interlace', 'holy', 'christian', 'eastern', 'lvsborg']\n",
      "CBOW TOP    : christianity ['attempting', 'compared', 'equipped', 'besides', 'accomplished', 'lesser', 'suspected', 'repeatedly', 'despite', 'presented']\n",
      "\n",
      "SKIPGRAM TOP: islam ['roman', 'external', 'see', 'lampooning', 'catholic', 'leptis', 'eastern', 'among', 'ancient', 'ermey']\n",
      "CBOW TOP    : islam ['attempting', 'compared', 'equipped', 'suspected', 'accomplished', 'despite', 'presented', 'besides', 'lesser', 'repeatedly']\n",
      "\n",
      "SKIPGRAM TOP: buddhism ['th', 'eso', 'roman', 'lampooning', 'zehn', 'akhmatova', 'msdn', 'antonietta', 'reinterred', 'prioress']\n",
      "CBOW TOP    : buddhism ['compared', 'attempting', 'equipped', 'accomplished', 'besides', 'suspected', 'lesser', 'despite', 'repeatedly', 'presented']\n",
      "\n",
      "SKIPGRAM TOP: catholic ['roman', 'catholic', 'lampooning', 'external', 'christian', 'th', 'corporis', 'holy', 'orthodox', 'sagres']\n",
      "CBOW TOP    : catholic ['nathaniel', 'comte', 'algeria', 'rand', 'andre', 'willard', 'huxley', 'anchor', 'anarchist', 'christie']\n",
      "\n",
      "SKIPGRAM TOP: army ['bmg', 'sorely', 'war', 'underling', 'during', 'karad', 'krupskaya', 'bienville', 'miast', 'lilia']\n",
      "CBOW TOP    : army ['nathaniel', 'algeria', 'comte', 'andre', 'rand', 'willard', 'huxley', 'anchor', 'anarchist', 'christie']\n",
      "\n",
      "SKIPGRAM TOP: navy ['bungled', 'boyac', 'kernot', 'bmg', 'macleish', 'schwarzenberg', 'wieliczka', 'citta', 'dene', 'homeward']\n",
      "CBOW TOP    : navy ['nathaniel', 'comte', 'rand', 'algeria', 'andre', 'willard', 'anchor', 'huxley', 'christie', 'anarchist']\n",
      "\n",
      "SKIPGRAM TOP: troops ['eso', 'during', 'bmg', 'bienville', 'krupskaya', 'war', 'raspberries', 'upi', 'hobhouse', 'buscetta']\n",
      "CBOW TOP    : troops ['nathaniel', 'comte', 'algeria', 'rand', 'andre', 'willard', 'anchor', 'huxley', 'anarchist', 'austrians']\n",
      "\n",
      "SKIPGRAM TOP: battle ['during', 'war', 'bmg', 'inconstant', 'upi', 'consultum', 'buscetta', 'eso', 'civil', 'montacute']\n",
      "CBOW TOP    : battle ['nathaniel', 'comte', 'algeria', 'rand', 'andre', 'willard', 'anchor', 'huxley', 'christie', 'asteroid']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/Patron/github-projects/embeddings\")\n",
    "from pretraining.word2vec.cbow import CBOWSGNS\n",
    "from pretraining.word2vec.skipgram import SkipGramSGNS\n",
    "skipgram_model = SkipGramSGNS.load('../../results/skipgram')\n",
    "cbow_model = CBOWSGNS.load('../../results/cbow')\n",
    "\n",
    "def category_top_nearest(model, anchor, topn=10):\n",
    "    M = (model.W_in + model.W_out) / 2\n",
    "    M = M / (np.linalg.norm(M,axis=1,keepdims=True)+1e-9)\n",
    "    v = model.W_in[model.word2id[anchor]]\n",
    "    v = v / (np.linalg.norm(v)+1e-9)\n",
    "    sims = M @ v\n",
    "    order = np.argsort(-sims)\n",
    "    return [model.id2word[i] for i in order[:topn]]\n",
    "\n",
    "stable = [\n",
    "    \"king\",\"queen\",\"prince\",\"emperor\",\n",
    "    \"france\",\"germany\",\"england\",\"russia\",\n",
    "    \"christianity\",\"islam\",\"buddhism\",\"catholic\",\n",
    "    \"army\",\"navy\",\"troops\",\"battle\",\n",
    "]\n",
    "\n",
    "for w in stable:\n",
    "    print(\"SKIPGRAM TOP:\", w, category_top_nearest(skipgram_model,w,10))\n",
    "    print(\"CBOW TOP    :\", w, category_top_nearest(cbow_model,w,10))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b212f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(model, word, topn=10):\n",
    "    import numpy as np\n",
    "    vecs = (model.W_in + model.W_out) / 2.0\n",
    "    v = vecs[model.word2id[word]]\n",
    "    sims = vecs @ v / (np.linalg.norm(vecs,axis=1)*np.linalg.norm(v)+1e-9)\n",
    "    order = np.argsort(-sims)\n",
    "    return [(model.id2word[i], float(sims[i])) for i in order[1:topn+1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed24cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('forces', 0.9961369633674622), ('army', 0.995850682258606), ('ii', 0.9958368539810181), ('nazi', 0.9958155155181885), ('germany', 0.9957225322723389), ('allied', 0.9953802227973938), ('troops', 0.9953007698059082), ('outbreak', 0.9952908158302307), ('fought', 0.9951883554458618), ('battle', 0.9949401021003723)]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar(model, \"war\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9812693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.9977585077285767), ('son', 0.9977362751960754), ('prince', 0.9971786737442017), ('daughter', 0.9970829486846924), ('pope', 0.9969437122344971), ('succeeded', 0.9969127774238586), ('reign', 0.9968228936195374), ('emperor', 0.9967514276504517), ('henry', 0.996737003326416), ('brother', 0.996713399887085)]\n",
      "[('berlin', 0.9994198083877563), ('vienna', 0.9992685317993164), ('lincoln', 0.9992021918296814), ('florence', 0.9991916418075562), ('milan', 0.9991791844367981), ('moscow', 0.9991526007652283), ('clown', 0.9991336464881897), ('abraham', 0.999121904373169), ('munich', 0.9991217255592346), ('oswald', 0.9991183876991272)]\n"
     ]
    }
   ],
   "source": [
    "print(most_similar(model, \"king\"))\n",
    "print(most_similar(model, \"paris\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18371b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king queen 0.8503580093383789\n",
      "king man 0.36603087186813354\n",
      "king woman 0.28577324748039246\n",
      "king dog 0.3268983066082001\n",
      "paris france 0.4163320064544678\n",
      "paris london 0.7193044424057007\n",
      "cat dog 0.5459689497947693\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def cosine(a,b): \n",
    "    return float(a @ b / (np.linalg.norm(a)*np.linalg.norm(b)))\n",
    "\n",
    "pairs = [\n",
    "    (\"king\",\"queen\"),\n",
    "    (\"king\",\"man\"),\n",
    "    (\"king\",\"woman\"),\n",
    "    (\"king\",\"dog\"),\n",
    "    (\"paris\",\"france\"),\n",
    "    (\"paris\",\"london\"),\n",
    "    (\"cat\",\"dog\")\n",
    "]\n",
    "\n",
    "for w1, w2 in pairs:\n",
    "    if w1 in model.word2id and w2 in model.word2id:\n",
    "        v1 = model.W_in[model.word2id[w1]]\n",
    "        v2 = model.W_in[model.word2id[w2]]\n",
    "        print(w1, w2, cosine(v1,v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ee2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = [\"king\",\"queen\",\"man\",\"woman\",\"paris\",\"france\",\"london\",\"england\",\"cat\",\"dog\",\"computer\",\"laptop\"]\n",
    "vecs = np.array([model.W_in[model.word2id[w]] for w in words if w in model.word2id])\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=8, random_state=42)\n",
    "xy = tsne.fit_transform(vecs)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i,w in enumerate(words):\n",
    "    if w in model.word2id:\n",
    "        plt.scatter(xy[i,0],xy[i,1])\n",
    "        plt.text(xy[i,0]+0.01, xy[i,1]+0.01, w)\n",
    "plt.title(\"TSNE sanity cluster check\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f54a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/Users/Patron/github-projects/embeddings\")\n",
    "from pretraining.utils.benchmark_datasets import EmbeddingBenchmarkDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_matrix_for_eval(model, which=\"combined\"):\n",
    "    M = (model.W_in + model.W_out) / 2.0 if which==\"combined\" else \\\n",
    "        (model.W_in if which==\"in\" else model.W_out)\n",
    "    M = M.copy()\n",
    "    # mean-center per dimension\n",
    "    M -= M.mean(axis=0, keepdims=True)\n",
    "    # row-normalize\n",
    "    M /= (np.linalg.norm(M, axis=1, keepdims=True) + 1e-9)\n",
    "    return M\n",
    "\n",
    "M = prepare_matrix_for_eval(model, which=\"combined\")\n",
    "w2i = model.word2id; i2w = model.id2word\n",
    "\n",
    "def most_similar_prepared(M, w, topn=10):\n",
    "    v = M[w2i[w]]\n",
    "    sims = M @ v\n",
    "    order = np.argsort(-sims)\n",
    "    return [(i2w[i], float(sims[i])) for i in order[1:topn+1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58c5572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king queen man woman\n",
      "[('man', 0.9958233833312988), ('woman', 0.9956870079040527), ('money', 0.9952985644340515), ('loved', 0.9950323104858398), ('herself', 0.9949503540992737)]\n",
      "\n",
      "paris france london england\n",
      "[('france', 0.9984983801841736), ('netherlands', 0.9984973669052124), ('britain', 0.9980919361114502), ('spain', 0.9980418682098389), ('italy', 0.9979803562164307)]\n",
      "\n",
      "france paris germany berlin\n",
      "[('paris', 0.9984679818153381), ('berlin', 0.9980963468551636), ('reconstruction', 0.9980744123458862), ('moscow', 0.9979672431945801), ('franco', 0.9979330897331238)]\n",
      "\n",
      "apple fruit carrot vegetable\n",
      "[('albinoni', -0.37984156608581543), ('sauna', -0.3893294334411621), ('births', -0.3918601870536804), ('fforde', -0.3957656919956207), ('nazwy', -0.4002169072628021)]\n",
      "\n",
      "car automobile plane aircraft\n",
      "[('plane', 0.9978063106536865), ('algebra', 0.9970730543136597), ('linear', 0.9970618486404419), ('finite', 0.997042179107666), ('dimensional', 0.9970002174377441)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "semantic_tests = [\n",
    "    (\"king\",\"queen\",\"man\",\"woman\"),\n",
    "    (\"paris\",\"france\",\"london\",\"england\"),\n",
    "    (\"france\",\"paris\",\"germany\",\"berlin\"),\n",
    "    (\"apple\",\"fruit\",\"carrot\",\"vegetable\"),\n",
    "    (\"car\",\"automobile\",\"plane\",\"aircraft\")\n",
    "]\n",
    "for a,b,c,d in semantic_tests:\n",
    "    print(a,b,c,d)\n",
    "    print(analogy_3cosadd(model,a,b,c)[:5])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0af2515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:running :: swim:?\n",
      "[('lice', 0.9815119504928589), ('story', 0.9814983606338501), ('coates', 0.9812896251678467), ('quasar', 0.9811702370643616), ('cowardice', 0.9811632633209229)]\n",
      "run:running :: swim:swimming | predicted=lice | correct=False\n",
      "\n",
      "walk:walking :: talk:?\n",
      "[('talk', 0.9989298582077026), ('cinema', 0.9985308647155762), ('guy', 0.9985108971595764), ('mad', 0.998444139957428), ('wise', 0.9984428286552429)]\n",
      "walk:walking :: talk:talking | predicted=talk | correct=False\n",
      "\n",
      "nation:nations :: state:?\n",
      "[('state', 0.9992780089378357), ('federal', 0.9980740547180176), ('security', 0.9974332451820374), ('nations', 0.9974052906036377), ('administration', 0.9972826838493347)]\n",
      "nation:nations :: state:states | predicted=state | correct=False\n",
      "\n",
      "program:programs :: computer:?\n",
      "[('computer', 0.99893718957901), ('software', 0.9968540668487549), ('systems', 0.9964869022369385), ('applications', 0.9959800243377686), ('digital', 0.9958880543708801)]\n",
      "program:programs :: computer:computers | predicted=computer | correct=False\n",
      "\n",
      "day:days :: year:?\n",
      "[('year', 0.9964279532432556), ('days', 0.9960634112358093), ('months', 0.9957658648490906), ('last', 0.9947998523712158), ('shortly', 0.9945429563522339)]\n",
      "day:days :: year:years | predicted=year | correct=False\n",
      "\n",
      "cat:cats :: dog:?\n",
      "[('dog', 0.9993654489517212), ('cats', 0.9991167783737183), ('fashion', 0.9989619255065918), ('agave', 0.998914361000061), ('memories', 0.9989124536514282)]\n",
      "cat:cats :: dog:dogs | predicted=dog | correct=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def analogy_3cosadd(model, a,b,c, topn=5):\n",
    "    M = (model.W_in + model.W_out) / 2.0\n",
    "    w2i = model.word2id\n",
    "    \n",
    "    v = M[w2i[b]] - M[w2i[a]] + M[w2i[c]]\n",
    "    \n",
    "    # normalize BOTH properly\n",
    "    M_norm = M / (np.linalg.norm(M, axis=1, keepdims=True) + 1e-9)\n",
    "    v = v / (np.linalg.norm(v) + 1e-9)\n",
    "    \n",
    "    sims = M_norm @ v\n",
    "    order = np.argsort(-sims)\n",
    "    return [(model.id2word[i], float(sims[i])) for i in order[:topn]]\n",
    "\n",
    "tests = [\n",
    "    (\"run\",\"running\",\"swim\",\"swimming\"),\n",
    "    (\"walk\",\"walking\",\"talk\",\"talking\"),\n",
    "    (\"nation\",\"nations\",\"state\",\"states\"),\n",
    "    (\"program\",\"programs\",\"computer\",\"computers\"),\n",
    "    (\"day\",\"days\",\"year\",\"years\"),\n",
    "    (\"cat\",\"cats\",\"dog\",\"dogs\"),\n",
    "]\n",
    "for a,b,c,d in tests:\n",
    "    print(f\"{a}:{b} :: {c}:?\")\n",
    "    print(analogy_3cosadd(model,a,b,c,topn=5))\n",
    "    pred = analogy_3cosadd(model,a,b,c,topn=3)[0][0]\n",
    "    print(f\"{a}:{b} :: {c}:{d} | predicted={pred} | correct={pred==d}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0944fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = [\"smaller\",\"shorter\",\"slower\",\"talking\",\"swimming\",\n",
    "         \"years\",\"states\",\"computers\"]\n",
    "for w in probe:\n",
    "    print(w, w in model.word2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c05bdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'big': True, 'bigger': True, 'small': True, 'smaller': True}\n",
      "{'long': True, 'longer': True, 'short': True, 'shorter': True}\n",
      "{'quick': True, 'quicker': True, 'slow': True, 'slower': True}\n",
      "{'run': True, 'running': True, 'play': True, 'playing': True}\n",
      "{'walk': True, 'walking': True, 'swim': True, 'swimming': True}\n",
      "{'day': True, 'days': True, 'year': True, 'years': True}\n",
      "{'nation': True, 'nations': True, 'state': True, 'states': True}\n",
      "{'program': True, 'programs': True, 'computer': True, 'computers': True}\n"
     ]
    }
   ],
   "source": [
    "def vocab_check(words):\n",
    "    return {w: (w in model.word2id) for w in words}\n",
    "\n",
    "print(vocab_check([\"big\",\"bigger\",\"small\",\"smaller\"]))\n",
    "print(vocab_check([\"long\",\"longer\",\"short\",\"shorter\"]))\n",
    "print(vocab_check([\"quick\",\"quicker\",\"slow\",\"slower\"]))\n",
    "print(vocab_check([\"run\",\"running\",\"play\",\"playing\"]))\n",
    "print(vocab_check([\"walk\",\"walking\",\"swim\",\"swimming\"]))\n",
    "print(vocab_check([\"day\",\"days\",\"year\",\"years\"]))\n",
    "print(vocab_check([\"nation\",\"nations\",\"state\",\"states\"]))\n",
    "print(vocab_check([\"program\",\"programs\",\"computer\",\"computers\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f34473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# load the same tokenized list-of-lists you trained on\n",
    "tok = loader.load_text8(chunk_size=256)  # or however you cached it\n",
    "cnt = Counter(w for s in tok for w in s)\n",
    "for w in probe:\n",
    "    print(w, cnt[w])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e19e62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV analogies kept: 6 / 6\n"
     ]
    }
   ],
   "source": [
    "def keep_iv(quads, word2id):\n",
    "    iv = []\n",
    "    for a,b,c,d in quads:\n",
    "        if all(w in word2id for w in (a,b,c,d)):\n",
    "            iv.append((a,b,c,d))\n",
    "    return iv\n",
    "\n",
    "quads = [\n",
    "    (\"big\",\"bigger\",\"small\",\"smaller\"),\n",
    "    (\"long\",\"longer\",\"short\",\"shorter\"),\n",
    "    (\"run\",\"running\",\"play\",\"playing\"),\n",
    "    (\"day\",\"days\",\"year\",\"years\"),\n",
    "    (\"nation\",\"nations\",\"state\",\"states\"),\n",
    "    (\"program\",\"programs\",\"computer\",\"computers\")\n",
    "]\n",
    "iv_quads = keep_iv(quads, model.word2id)\n",
    "print(\"IV analogies kept:\", len(iv_quads), \"/\", len(quads))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91a200c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big:bigger :: small:?\n",
      "Predicted: [('small', 0.9946258068084717), ('large', 0.9945324063301086), ('low', 0.9898232817649841), ('relatively', 0.9897944927215576), ('water', 0.9895567893981934), ('areas', 0.9892217516899109), ('range', 0.9883784651756287), ('lower', 0.9883126020431519), ('higher', 0.9882976412773132), ('larger', 0.9882911443710327)]\n",
      "Expected: smaller\n",
      "\n",
      "long:longer :: short:?\n",
      "Predicted: [('collection', 0.9951975345611572), ('genre', 0.9951460361480713), ('versions', 0.9950860738754272), ('cards', 0.9950084686279297), ('publish', 0.9949991106987), ('molecular', 0.994952380657196), ('memory', 0.9949322938919067), ('abstract', 0.9949235320091248), ('ethernet', 0.9949174523353577), ('aspects', 0.9949017763137817)]\n",
      "Expected: shorter\n",
      "\n",
      "quick:quicker :: slow:?\n",
      "Predicted: [('quicker', 0.9981658458709717), ('slow', 0.9980124235153198), ('decrease', 0.9976077079772949), ('strategies', 0.9975178837776184), ('rainfall', 0.9974513053894043), ('unemployment', 0.9974422454833984), ('oil', 0.9974397420883179), ('offshore', 0.9974387288093567), ('capacity', 0.9974256753921509), ('rates', 0.9974122643470764)]\n",
      "Expected: slower\n",
      "\n",
      "run:running :: play:?\n",
      "Predicted: [('play', 0.9984977841377258), ('plays', 0.9974396228790283), ('playing', 0.9974274635314941), ('featured', 0.9971939325332642), ('played', 0.9969240427017212), ('appeared', 0.9968641996383667), ('movies', 0.996789813041687), ('band', 0.9966650009155273), ('stage', 0.99664705991745), ('fans', 0.9966335892677307)]\n",
      "Expected: playing\n",
      "\n",
      "walk:walking :: swim:?\n",
      "Predicted: [('tod', 0.9920241832733154), ('brouwer', 0.9919021725654602), ('transformers', 0.9917383790016174), ('erickson', 0.9916525483131409), ('dunn', 0.9916306734085083), ('sayles', 0.991611123085022), ('prefect', 0.9915949106216431), ('sequencing', 0.9915174841880798), ('experimentally', 0.991509735584259), ('walking', 0.9914782047271729)]\n",
      "Expected: swimming\n",
      "\n",
      "day:days :: year:?\n",
      "Predicted: [('year', 0.9964278936386108), ('days', 0.9960633516311646), ('months', 0.9957658648490906), ('last', 0.9947997331619263), ('shortly', 0.9945428967475891), ('fifteen', 0.9944956302642822), ('next', 0.9944440126419067), ('years', 0.9943665862083435), ('month', 0.9943096041679382), ('thirty', 0.994221031665802)]\n",
      "Expected: years\n",
      "\n",
      "nation:nations :: state:?\n",
      "Predicted: [('state', 0.9992780685424805), ('federal', 0.998073935508728), ('security', 0.9974331259727478), ('nations', 0.9974054098129272), ('administration', 0.9972827434539795), ('constitutional', 0.9972435832023621), ('organization', 0.9970954656600952), ('states', 0.997085690498352), ('congress', 0.9970067143440247), ('independent', 0.9970043301582336)]\n",
      "Expected: states\n",
      "\n",
      "program:programs :: computer:?\n",
      "Predicted: [('computer', 0.9989372491836548), ('software', 0.9968541264533997), ('systems', 0.9964869022369385), ('applications', 0.9959799647331238), ('digital', 0.9958879947662354), ('using', 0.9954118728637695), ('data', 0.9953728318214417), ('programs', 0.9952616691589355), ('hardware', 0.9951207637786865), ('electronic', 0.9951024651527405)]\n",
      "Expected: computers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tests = [\n",
    "    (\"big\",\"bigger\",\"small\",\"smaller\"),\n",
    "    (\"long\",\"longer\",\"short\",\"shorter\"),\n",
    "    (\"quick\",\"quicker\",\"slow\",\"slower\"),\n",
    "    (\"run\",\"running\",\"play\",\"playing\"),\n",
    "    (\"walk\",\"walking\",\"swim\",\"swimming\"),\n",
    "    (\"day\",\"days\",\"year\",\"years\"),\n",
    "    (\"nation\",\"nations\",\"state\",\"states\"),\n",
    "    (\"program\",\"programs\",\"computer\",\"computers\"),\n",
    "]\n",
    "for a,b,c,d in tests:\n",
    "    print(f\"{a}:{b} :: {c}:?\")\n",
    "    print(\"Predicted:\", analogy_3cosadd(model,a,b,c,topn=10))\n",
    "    print(\"Expected:\", d)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretraining.utils.benchmark_datasets import EmbeddingBenchmarkDatasets\n",
    "from pretraining.utils.evaluation.eval_intrinsic import evaluate_embeddings\n",
    "from skipgram import SkipGramSGNS\n",
    "from pathlib import Path\n",
    "import json\n",
    "model = SkipGramSGNS.load('../../results/skipgram')\n",
    "word_vecs = model.export_word_vectors(which=\"combined\")\n",
    "loader = EmbeddingBenchmarkDatasets(data_dir=\"datasets\")\n",
    "analogy_pairs = loader.get_word_analogy_pairs()\n",
    "similarity_pairs = loader.get_word_similarity_pairs()\n",
    "\n",
    "# convert our (word -> vector) dict form from your export_word_vectors()\n",
    "# NOTE: this returns dict[str, np.ndarray]\n",
    "intrinsic_results = evaluate_embeddings(\n",
    "    word_vectors=word_vecs,\n",
    "    similarity_pairs=[(*p, 0.0) if len(p)==2 else p for p in similarity_pairs],  # our similarity had gold score included already in your new updated pairs\n",
    "    analogy_quads=[tuple(a) for a in analogy_pairs],\n",
    "    topk=1,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# save\n",
    "model_dir = Path(\"../../results/skipgram\")\n",
    "intrinsic_path = model_dir / \"intrinsic_eval.json\"\n",
    "with open(intrinsic_path, \"w\") as f:\n",
    "    json.dump(intrinsic_results, f, indent=2)\n",
    "print(\"[SkipGram] Intrinsic Eval:\", intrinsic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbow import CBOWSGNS\n",
    "model = CBOWSGNS.load('../../results/cbow')\n",
    "\n",
    "word_vecs = model.export_word_vectors(which=\"combined\")\n",
    "loader = EmbeddingBenchmarkDatasets(data_dir=\"datasets\")\n",
    "analogy_pairs = loader.get_word_analogy_pairs()\n",
    "similarity_pairs = loader.get_word_similarity_pairs()\n",
    "\n",
    "# convert our (word -> vector) dict form from your export_word_vectors()\n",
    "# NOTE: this returns dict[str, np.ndarray]\n",
    "intrinsic_results = evaluate_embeddings(\n",
    "    word_vectors=word_vecs,\n",
    "    similarity_pairs=[(*p, 0.0) if len(p)==2 else p for p in similarity_pairs],  # our similarity had gold score included already in your new updated pairs\n",
    "    analogy_quads=[tuple(a) for a in analogy_pairs],\n",
    "    topk=1,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# save\n",
    "model_dir = Path(\"../../results/cbow\")\n",
    "intrinsic_path = model_dir / \"intrinsic_eval.json\"\n",
    "with open(intrinsic_path, \"w\") as f:\n",
    "    json.dump(intrinsic_results, f, indent=2)\n",
    "print(\"[CBOW] Intrinsic Eval:\", intrinsic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_words = [\"hydrogen\",\"oxygen\",\"carbon\",\"germany\",\"france\",\"europe\",\"napoleon\",\"hitler\",\"allies\",\"axis\", \"christianity\",\"islam\",\"buddhism\",\"judaism\",\"gravity\",\"relativity\",\"quantum\",\"electron\",\"proton\",\"neutron\"]\n",
    "for w in probe_words:\n",
    "    print(w, most_similar(model,w,topn=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f4b4272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religions coherence: 0.62820596\n",
      "WW2 coherence: 0.6164529\n",
      "Math coherence: 0.7367727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "def category_coherence(words):\n",
    "    import numpy as np\n",
    "    sims=[]\n",
    "    for i in range(len(words)):\n",
    "        for j in range(i+1,len(words)):\n",
    "            if words[i] in model.word2id and words[j] in model.word2id:\n",
    "                v1 = model.W_in[model.word2id[words[i]]]\n",
    "                v2 = model.W_in[model.word2id[words[j]]]\n",
    "                sims.append(cosine(v1.reshape(1,-1),v2.reshape(1,-1))[0][0])\n",
    "    return np.mean(sims)\n",
    "\n",
    "religions = [\"christianity\",\"islam\",\"judaism\",\"buddhism\"]\n",
    "ww2 = [\"hitler\",\"napoleon\",\"troops\",\"army\",\"germany\"]\n",
    "math = [\"geometry\",\"algebra\",\"calculus\",\"equation\",\"theorem\"]\n",
    "\n",
    "print(\"Religions coherence:\", category_coherence(religions))\n",
    "print(\"WW2 coherence:\", category_coherence(ww2))\n",
    "print(\"Math coherence:\", category_coherence(math))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32d91a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries coherence: 0.84353924\n",
      "Instruments coherence: 0.60676914\n",
      "Sports coherence: 0.84160763\n",
      "Tech Companies coherence: 0.5220221\n",
      "Elements coherence: 0.756093\n",
      "Royalty coherence: 0.75009465\n"
     ]
    }
   ],
   "source": [
    "countries = [\"poland\", \"germany\", \"france\", \"spain\", \"italy\"]\n",
    "instruments = [\"piano\", \"guitar\", \"drums\", \"violin\"]\n",
    "sports = [\"football\", \"basketball\", \"baseball\", \"tennis\"]\n",
    "tech_companies = [\"apple\", \"microsoft\", \"ibm\", \"intel\", \"google\"]\n",
    "elements = [\"hydrogen\", \"oxygen\", \"nitrogen\", \"carbon\"]\n",
    "royalty = [\"king\", \"queen\", \"prince\", \"duke\", \"emperor\"]\n",
    "\n",
    "print(\"Countries coherence:\", category_coherence(countries))\n",
    "print(\"Instruments coherence:\", category_coherence(instruments))\n",
    "print(\"Sports coherence:\", category_coherence(sports))\n",
    "print(\"Tech Companies coherence:\", category_coherence(tech_companies))\n",
    "print(\"Elements coherence:\", category_coherence(elements))\n",
    "print(\"Royalty coherence:\", category_coherence(royalty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac54c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_words = [\"king\",\"paris\",\"computer\",\"apple\",\"war\",\"music\"]\n",
    "for w in probe_words:\n",
    "    print(w, most_similar(model,w,topn=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7985b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king 0.8834876484952464\n",
      "paris 0.8720277915100092\n",
      "computer 0.8057821944022688\n"
     ]
    }
   ],
   "source": [
    "def cluster_coherence(word, topn=10):\n",
    "    sims = most_similar(model,word,topn)\n",
    "    words = [w for w,_ in sims]\n",
    "    vecs = np.array([model.W_in[model.word2id[w]] for w in words])\n",
    "    S = np.corrcoef(vecs @ vecs.T)\n",
    "    return np.mean(S)\n",
    "\n",
    "for w in [\"king\",\"paris\",\"computer\"]:\n",
    "    print(w, cluster_coherence(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801c2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
